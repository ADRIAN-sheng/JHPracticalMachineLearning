{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Encodings**\n",
        "Considerations:\n",
        "- Label Encoding: It's generally used for ordinal variables or as a preprocessing step before applying certain algorithms that require labels to be encoded as integers. It assigns a unique integer to each category.\n",
        "\n",
        "- Dummy Encoding: This approach is widely used for nominal variables where no ordinal relationship exists. The get_dummies method from pandas creates a new column for each category and is suitable for most machine learning models, helping them understand categorical data without imposing an artificial order.\n",
        "\n",
        "- Missing Values: Before encoding, handle missing values in your data, as trying to encode NaN values may lead to errors. The dataset loaded may contain missing values, especially in columns like 'embarked'.\n",
        "\n",
        "Selection of Encoding Method: The choice between label encoding and dummy encoding depends on the specific requirements of your model and the nature of your categorical data (ordinal vs. nominal)."
      ],
      "metadata": {
        "id": "SPhBzor601Ne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhqU1qWV0w-B",
        "outputId": "99ff47a2-dfd0-41fa-868d-dee3ae90a52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ORIGINAL dataframe\n",
            "\n",
            "   pclass                                             name     sex      age  \\\n",
            "0     1.0                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
            "1     1.0                   Allison, Master. Hudson Trevor    male   0.9167   \n",
            "2     1.0                     Allison, Miss. Helen Loraine  female   2.0000   \n",
            "3     1.0             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
            "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
            "\n",
            "   sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
            "0    0.0    0.0   24160  211.3375       B5        S     2   None   \n",
            "1    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
            "2    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
            "3    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
            "4    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
            "\n",
            "                         home.dest  \n",
            "0                     St Louis, MO  \n",
            "1  Montreal, PQ / Chesterville, ON  \n",
            "2  Montreal, PQ / Chesterville, ON  \n",
            "3  Montreal, PQ / Chesterville, ON  \n",
            "4  Montreal, PQ / Chesterville, ON  \n",
            "\n",
            " TRANSFORMED dataframe\n",
            "\n",
            "   pclass                                             name      age  sibsp  \\\n",
            "0     1.0                    Allen, Miss. Elisabeth Walton  29.0000    0.0   \n",
            "1     1.0                   Allison, Master. Hudson Trevor   0.9167    1.0   \n",
            "2     1.0                     Allison, Miss. Helen Loraine   2.0000    1.0   \n",
            "3     1.0             Allison, Mr. Hudson Joshua Creighton  30.0000    1.0   \n",
            "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  25.0000    1.0   \n",
            "\n",
            "   parch  ticket      fare    cabin  boat   body  \\\n",
            "0    0.0   24160  211.3375       B5     2   None   \n",
            "1    2.0  113781  151.5500  C22 C26    11    NaN   \n",
            "2    2.0  113781  151.5500  C22 C26  None    NaN   \n",
            "3    2.0  113781  151.5500  C22 C26  None  135.0   \n",
            "4    2.0  113781  151.5500  C22 C26  None    NaN   \n",
            "\n",
            "                         home.dest  embarked_label  sex_label  \\\n",
            "0                     St Louis, MO               2          0   \n",
            "1  Montreal, PQ / Chesterville, ON               2          1   \n",
            "2  Montreal, PQ / Chesterville, ON               2          0   \n",
            "3  Montreal, PQ / Chesterville, ON               2          1   \n",
            "4  Montreal, PQ / Chesterville, ON               2          0   \n",
            "\n",
            "   embarked_dummy_Q  embarked_dummy_S  sex_dummy_male  \n",
            "0                 0                 1               0  \n",
            "1                 0                 1               1  \n",
            "2                 0                 1               0  \n",
            "3                 0                 1               1  \n",
            "4                 0                 1               0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset\n",
        "titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
        "df = titanic.data\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"\\n ORIGINAL dataframe\\n\")\n",
        "print(df.head())\n",
        "\n",
        "# Example categorical features for demonstration\n",
        "categorical_features = ['embarked', 'sex']\n",
        "\n",
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for column in categorical_features:\n",
        "    df[column + '_label'] = label_encoder.fit_transform(df[column].astype(str))\n",
        "\n",
        "# Dummy (One-Hot) Encoding\n",
        "# Pandas get_dummies function is used for one-hot encoding. `drop_first=True` can be used to drop the first level to avoid dummy variable trap.\n",
        "df = pd.get_dummies(df, columns=categorical_features, prefix=[f\"{col}_dummy\" for col in categorical_features], drop_first=True)\n",
        "\n",
        "# Display the transformed DataFrame\n",
        "print(\"\\n TRANSFORMED dataframe\\n\")\n",
        "print(df.head())"
      ]
    }
  ]
}